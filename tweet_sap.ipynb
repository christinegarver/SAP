{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from torchvision import datasets, transforms, models\n",
    "import re\n",
    "import string\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                              tweet\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file into pandas dataframe and name columns\n",
    "data_dir = 'data/training.csv'\n",
    "cols = ['sentiment', 'tweet']\n",
    "\n",
    "train = pd.read_csv(data_dir, encoding = \"ISO-8859-1\", header=None, usecols=[0,5], names=cols)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = train[0:10000]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000\n",
      "0\n",
      "800000\n",
      "[0 4]\n"
     ]
    }
   ],
   "source": [
    "#Observe Data\n",
    "print((train['sentiment'] == 0).sum())\n",
    "print((train['sentiment'] == 2).sum())\n",
    "print((train['sentiment'] == 4).sum())\n",
    "print((train['sentiment'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Scale the Data so 1 represents positive sentiment and 0 negative sentiment\n",
    "\"\"\"\n",
    "train['sentiment'] = train['sentiment']/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentiment                                              tweet\n",
      "0        0.0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1        0.0  is upset that he can't update his Facebook by ...\n",
      "2        0.0  @Kenichan I dived many times for the ball. Man...\n",
      "3        0.0    my whole body feels itchy and like its on fire \n",
      "4        0.0  @nationwideclass no, it's not behaving at all....\n",
      "800000\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print((train['sentiment'] == 0.0).sum())\n",
    "print((train['sentiment'] == 1.0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Process the tweets to remove not very significant words/symbols\n",
    "\"\"\"\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "def cleanText(tweet):\n",
    "    # remove punctuation marks\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # remove \"@\" symbol\n",
    "    remove_at = re.sub(r'@[A-Za-z0-9]+',\"\", tweet)\n",
    "    # remove url's\n",
    "    remove_url = re.sub('https?://[A-Za-z0-9./]+',\"\", remove_at)\n",
    "    \n",
    "    #remove stopwords\n",
    "    text = word_tokenize(remove_url)\n",
    "    clean = [word for word in text if word not in stopwords.words('english')]\n",
    "    \n",
    "    #lower case all letter\n",
    "    clean = [word.lower() for word in clean]\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinegarver/miniconda3/envs/sap/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: 1\n",
      "Loop: 2\n",
      "Loop: 3\n",
      "Loop: 4\n",
      "Loop: 5\n",
      "Loop: 6\n",
      "Loop: 7\n",
      "Loop: 8\n",
      "Loop: 9\n",
      "Loop: 10\n",
      "Loop: 11\n",
      "Loop: 12\n",
      "Loop: 13\n",
      "Loop: 14\n",
      "Loop: 15\n",
      "Loop: 16\n",
      "Loop: 17\n",
      "Loop: 18\n",
      "Loop: 19\n",
      "Loop: 20\n",
      "Loop: 21\n",
      "Loop: 22\n",
      "Loop: 23\n",
      "Loop: 24\n",
      "Loop: 25\n",
      "Loop: 26\n",
      "Loop: 27\n",
      "Loop: 28\n",
      "Loop: 29\n",
      "Loop: 30\n",
      "Loop: 31\n",
      "Loop: 32\n",
      "Loop: 33\n",
      "Loop: 34\n",
      "Loop: 35\n",
      "Loop: 36\n",
      "Loop: 37\n",
      "Loop: 38\n",
      "Loop: 39\n",
      "Loop: 40\n",
      "Loop: 41\n",
      "Loop: 42\n",
      "Loop: 43\n",
      "Loop: 44\n",
      "Loop: 45\n",
      "Loop: 46\n",
      "Loop: 47\n",
      "Loop: 48\n",
      "Loop: 49\n",
      "Loop: 50\n",
      "Loop: 51\n",
      "Loop: 52\n",
      "Loop: 53\n",
      "Loop: 54\n",
      "Loop: 55\n",
      "Loop: 56\n",
      "Loop: 57\n",
      "Loop: 58\n",
      "Loop: 59\n",
      "Loop: 60\n",
      "Loop: 61\n",
      "Loop: 62\n",
      "Loop: 63\n",
      "Loop: 64\n",
      "Loop: 65\n",
      "Loop: 66\n",
      "Loop: 67\n",
      "Loop: 68\n",
      "Loop: 69\n",
      "Loop: 70\n",
      "Loop: 71\n",
      "Loop: 72\n",
      "Loop: 73\n",
      "Loop: 74\n",
      "Loop: 75\n",
      "Loop: 76\n",
      "Loop: 77\n",
      "Loop: 78\n",
      "Loop: 79\n",
      "Loop: 80\n",
      "Loop: 81\n",
      "Loop: 82\n",
      "Loop: 83\n",
      "Loop: 84\n",
      "Loop: 85\n",
      "Loop: 86\n",
      "Loop: 87\n",
      "Loop: 88\n",
      "Loop: 89\n",
      "Loop: 90\n",
      "Loop: 91\n",
      "Loop: 92\n",
      "Loop: 93\n",
      "Loop: 94\n",
      "Loop: 95\n",
      "Loop: 96\n",
      "Loop: 97\n",
      "Loop: 98\n",
      "Loop: 99\n",
      "Loop: 100\n",
      "Loop: 101\n",
      "Loop: 102\n",
      "Loop: 103\n",
      "Loop: 104\n",
      "Loop: 105\n",
      "Loop: 106\n",
      "Loop: 107\n",
      "Loop: 108\n",
      "Loop: 109\n",
      "Loop: 110\n",
      "Loop: 111\n",
      "Loop: 112\n",
      "Loop: 113\n",
      "Loop: 114\n",
      "Loop: 115\n",
      "Loop: 116\n",
      "Loop: 117\n",
      "Loop: 118\n",
      "Loop: 119\n",
      "Loop: 120\n",
      "Loop: 121\n",
      "Loop: 122\n",
      "Loop: 123\n",
      "Loop: 124\n",
      "Loop: 125\n",
      "Loop: 126\n",
      "Loop: 127\n",
      "Loop: 128\n",
      "Loop: 129\n",
      "Loop: 130\n",
      "Loop: 131\n",
      "Loop: 132\n",
      "Loop: 133\n",
      "Loop: 134\n",
      "Loop: 135\n",
      "Loop: 136\n",
      "Loop: 137\n",
      "Loop: 138\n",
      "Loop: 139\n",
      "Loop: 140\n",
      "Loop: 141\n",
      "Loop: 142\n",
      "Loop: 143\n",
      "Loop: 144\n",
      "Loop: 145\n",
      "Loop: 146\n",
      "Loop: 147\n",
      "Loop: 148\n",
      "Loop: 149\n",
      "Loop: 150\n",
      "Loop: 151\n",
      "Loop: 152\n",
      "Loop: 153\n",
      "Loop: 154\n",
      "Loop: 155\n",
      "Loop: 156\n",
      "Loop: 157\n",
      "Loop: 158\n",
      "Loop: 159\n",
      "Loop: 160\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Tokenize the data in batches to see how fast the cleaning takes\n",
    "\"\"\"\n",
    "batch_size = 10000\n",
    "iters = train.shape[0]//batch_size\n",
    "i = 0\n",
    "\n",
    "\n",
    "for i in range(iters):\n",
    "    batch = train[i*batch_size:i*batch_size+batch_size]\n",
    "    batch['tweet'] = batch['tweet'].apply(cleanText)\n",
    "    t = pd.concat([train, batch], 1)\n",
    "    print(\"Loop: {}\".format(i + 1))\n",
    "    \n",
    "t = t.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[kenichan, i, dived, many, times, ball, manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, i, cant, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                              tweet\n",
       "0        0.0  [switchfoot, httptwitpiccom2y1zl, awww, thats,...\n",
       "1        0.0  [upset, cant, update, facebook, texting, might...\n",
       "2        0.0  [kenichan, i, dived, many, times, ball, manage...\n",
       "3        0.0            [whole, body, feels, itchy, like, fire]\n",
       "4        0.0  [nationwideclass, behaving, im, mad, i, cant, ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "One Hot Encode the Tweets so an array of 1, 0's represent presence of word in tweet\n",
    "Will only one-hot encode each tweet as it is inputted in the training model in order to save memory\n",
    "\"\"\"\n",
    "def oneHot_encode(one_hot, tweet_input):\n",
    "    for word in tweet_input['tweet']:\n",
    "        one_hot[word] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The dataframe 'one_hot' will represent a dataframe filled with zeros for each possibly word/symbol in the tweets\n",
    "Will then be used when one hot encoding each tweet while training\n",
    "Not enough memory to one hot encode all tweets at once\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "words = set()\n",
    "\n",
    "for index,row in t.iterrows():\n",
    "    for word in row['tweet']:\n",
    "        words.add(word)\n",
    "        \n",
    "zero_data = np.zeros(shape=(1,len(words)))\n",
    "one_hot = pd.DataFrame(zero_data,columns = words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theremuslupins</th>\n",
       "      <th>osquot</th>\n",
       "      <th>ñññ</th>\n",
       "      <th>lindslou10</th>\n",
       "      <th>cutiiex3</th>\n",
       "      <th>tourthen</th>\n",
       "      <th>stalkeees</th>\n",
       "      <th>thamelissashow</th>\n",
       "      <th>houstonlast</th>\n",
       "      <th>sarahshe</th>\n",
       "      <th>...</th>\n",
       "      <th>httptwitpiccom6io3t</th>\n",
       "      <th>httptwitpiccom4j1fs</th>\n",
       "      <th>agopentecost</th>\n",
       "      <th>hrrmph</th>\n",
       "      <th>stephie</th>\n",
       "      <th>humelation</th>\n",
       "      <th>raeraesunshine</th>\n",
       "      <th>emmyhall</th>\n",
       "      <th>chloekatee</th>\n",
       "      <th>cavaliersso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 850276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   theremuslupins  osquot  ñññ  lindslou10  cutiiex3  tourthen  stalkeees  \\\n",
       "0             0.0     0.0     0.0         0.0       0.0       0.0        0.0   \n",
       "\n",
       "   thamelissashow  houstonlast  sarahshe  ...  httptwitpiccom6io3t  \\\n",
       "0             0.0          0.0       0.0  ...                  0.0   \n",
       "\n",
       "   httptwitpiccom4j1fs  agopentecost  hrrmph  stephie  humelation  \\\n",
       "0                  0.0           0.0     0.0      0.0         0.0   \n",
       "\n",
       "   raeraesunshine  emmyhall  chloekatee  cavaliersso  \n",
       "0             0.0       0.0         0.0          0.0  \n",
       "\n",
       "[1 rows x 850276 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save tokenized data in csv\n",
    "\"\"\"\n",
    "tokenized_training = t\n",
    "tokenized_training.to_csv('tokenized_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save one hot encoded array in a csv\n",
    "\"\"\"\n",
    "encoded = one_hot\n",
    "encoded.to_csv('encode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinegarver/miniconda3/envs/sap/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[switchfoot, httptwitpiccom2y1zl, awww, thats,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[kenichan, i, dived, many, times, ball, manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, i, cant, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                              tweet\n",
       "0        0.0  [switchfoot, httptwitpiccom2y1zl, awww, thats,...\n",
       "1        0.0  [upset, cant, update, facebook, texting, might...\n",
       "2        0.0  [kenichan, i, dived, many, times, ball, manage...\n",
       "3        0.0            [whole, body, feels, itchy, like, fire]\n",
       "4        0.0  [nationwideclass, behaving, im, mad, i, cant, ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "load the tokenized tweets\n",
    "\"\"\"\n",
    "csv = 'tokenized_tweets.csv'\n",
    "clean_train = pd.read_csv(csv,index_col=0)\n",
    "clean_train['tweet'] = clean_train['tweet'].apply(literal_eval)\n",
    "clean_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theremuslupins</th>\n",
       "      <th>osquot</th>\n",
       "      <th>ñññ</th>\n",
       "      <th>lindslou10</th>\n",
       "      <th>cutiiex3</th>\n",
       "      <th>tourthen</th>\n",
       "      <th>stalkeees</th>\n",
       "      <th>thamelissashow</th>\n",
       "      <th>houstonlast</th>\n",
       "      <th>sarahshe</th>\n",
       "      <th>...</th>\n",
       "      <th>httptwitpiccom6io3t</th>\n",
       "      <th>httptwitpiccom4j1fs</th>\n",
       "      <th>agopentecost</th>\n",
       "      <th>hrrmph</th>\n",
       "      <th>stephie</th>\n",
       "      <th>humelation</th>\n",
       "      <th>raeraesunshine</th>\n",
       "      <th>emmyhall</th>\n",
       "      <th>chloekatee</th>\n",
       "      <th>cavaliersso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 850276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   theremuslupins  osquot  ñññ  lindslou10  cutiiex3  tourthen  stalkeees  \\\n",
       "0             0.0     0.0     0.0         0.0       0.0       0.0        0.0   \n",
       "\n",
       "   thamelissashow  houstonlast  sarahshe  ...  httptwitpiccom6io3t  \\\n",
       "0             0.0          0.0       0.0  ...                  0.0   \n",
       "\n",
       "   httptwitpiccom4j1fs  agopentecost  hrrmph  stephie  humelation  \\\n",
       "0                  0.0           0.0     0.0      0.0         0.0   \n",
       "\n",
       "   raeraesunshine  emmyhall  chloekatee  cavaliersso  \n",
       "0             0.0       0.0         0.0          0.0  \n",
       "\n",
       "[1 rows x 850276 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "load the one hot encoded array\n",
    "\"\"\"\n",
    "csv = 'encode.csv'\n",
    "encoded = pd.read_csv(csv,index_col=0)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.001350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.001720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.000820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850246</th>\n",
       "      <td>-0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850247</th>\n",
       "      <td>-0.000991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850248</th>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850249</th>\n",
       "      <td>-0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850250</th>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850251</th>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850252</th>\n",
       "      <td>-0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850253</th>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850254</th>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850255</th>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850256</th>\n",
       "      <td>0.000593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850257</th>\n",
       "      <td>-0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850258</th>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850259</th>\n",
       "      <td>-0.002125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850260</th>\n",
       "      <td>0.001893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261</th>\n",
       "      <td>-0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850262</th>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850263</th>\n",
       "      <td>-0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850264</th>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850265</th>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850266</th>\n",
       "      <td>-0.001441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850267</th>\n",
       "      <td>-0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850268</th>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850269</th>\n",
       "      <td>0.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850270</th>\n",
       "      <td>-0.000485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850271</th>\n",
       "      <td>-0.000336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850272</th>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850273</th>\n",
       "      <td>0.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850274</th>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850275</th>\n",
       "      <td>0.000396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850276 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      -0.000193\n",
       "1      -0.000530\n",
       "2       0.000721\n",
       "3       0.000135\n",
       "4      -0.000299\n",
       "5       0.000457\n",
       "6      -0.001350\n",
       "7       0.001373\n",
       "8      -0.000736\n",
       "9      -0.000253\n",
       "10     -0.000739\n",
       "11     -0.000386\n",
       "12      0.001135\n",
       "13      0.001211\n",
       "14      0.000104\n",
       "15      0.001909\n",
       "16      0.000132\n",
       "17     -0.000317\n",
       "18      0.000114\n",
       "19     -0.000294\n",
       "20      0.000369\n",
       "21      0.001872\n",
       "22      0.000491\n",
       "23      0.000131\n",
       "24      0.000392\n",
       "25     -0.001720\n",
       "26      0.000867\n",
       "27     -0.000069\n",
       "28     -0.000963\n",
       "29     -0.000820\n",
       "...          ...\n",
       "850246 -0.000073\n",
       "850247 -0.000991\n",
       "850248  0.000072\n",
       "850249 -0.000133\n",
       "850250  0.000009\n",
       "850251  0.000050\n",
       "850252 -0.001306\n",
       "850253  0.000332\n",
       "850254  0.001540\n",
       "850255  0.001202\n",
       "850256  0.000593\n",
       "850257 -0.000336\n",
       "850258  0.001944\n",
       "850259 -0.002125\n",
       "850260  0.001893\n",
       "850261 -0.000736\n",
       "850262  0.000588\n",
       "850263 -0.000450\n",
       "850264  0.001428\n",
       "850265  0.001688\n",
       "850266 -0.001441\n",
       "850267 -0.001462\n",
       "850268  0.000015\n",
       "850269  0.000507\n",
       "850270 -0.000485\n",
       "850271 -0.000336\n",
       "850272  0.000517\n",
       "850273  0.000897\n",
       "850274  0.002984\n",
       "850275  0.000396\n",
       "\n",
       "[850276 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "load weights array\n",
    "\"\"\"\n",
    "csv = 'weights_1_epoch.csv'\n",
    "w = pd.read_csv(csv,index_col=0)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "Name: i, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n",
      "(200, 2)\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "positives = clean_train[:200]\n",
    "negatives = clean_train[850000:850200]\n",
    "print(positives.shape)\n",
    "print(negatives.shape)\n",
    "print((positives['sentiment'] == 0).sum())\n",
    "print((negatives['sentiment'] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clean_train = clean_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.concat([positives, negatives])\n",
    "c.shape\n",
    "clean_train = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 850276)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Training Data:(1280000, 2)\n",
      "Training Neg:640333\n",
      "Training Pos:639667\n",
      "Validation Data:(80000, 2)\n",
      "Validation Neg:39957\n",
      "Validation Pos:40043\n",
      "Test Data:(240000, 2)\n",
      "Test Neg:119710\n",
      "Test Pos:120290\n",
      "         sentiment                                              tweet\n",
      "883393         1.0         [nicholasmw, 1, day, u, find, girl, worry]\n",
      "461479         0.0  [nothing, tv, im, desperate, entertained, im, ...\n",
      "103630         0.0  [very, excited, greys, tonight, not, happy, se...\n",
      "1031265        1.0            [2pms, great, song, nichkhun, hwaiting]\n",
      "219956         0.0                                  [my, teeth, hurt]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split data into training, test, and validation sets\n",
    "Will one-hot encode later to save memory\n",
    "\"\"\"\n",
    "\n",
    "data = clean_train\n",
    "\n",
    "#Training Date = 60%\n",
    "\n",
    "train=data.sample(frac=0.8,random_state=100)\n",
    "train.head()\n",
    "\n",
    "#Validation Data = 10%\n",
    "rest = data.loc[~data.index.isin(train.index), :]\n",
    "validation = rest.sample(frac=.25, random_state=100)\n",
    "validation.head()\n",
    "\n",
    "#Test Data = 30%\n",
    "ultimate_rest = rest.loc[~rest.index.isin(validation.index), :]\n",
    "test = ultimate_rest\n",
    "\n",
    "print(train.shape[1])\n",
    "\n",
    "print(\"Training Data:{}\".format(train.shape))\n",
    "print(\"Training Neg:{}\".format((train['sentiment'] == 0.0).sum()))\n",
    "print(\"Training Pos:{}\".format((train['sentiment'] == 1.0).sum()))\n",
    "\n",
    "print(\"Validation Data:{}\".format(validation.shape))\n",
    "print(\"Validation Neg:{}\".format((validation['sentiment'] == 0.0).sum()))\n",
    "print(\"Validation Pos:{}\".format((validation['sentiment'] == 1.0).sum()))\n",
    "\n",
    "print(\"Test Data:{}\".format(test.shape))\n",
    "print(\"Test Neg:{}\".format((test['sentiment'] == 0.0).sum()))\n",
    "print(\"Test Pos:{}\".format((test['sentiment'] == 1.0).sum()))\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data:(500, 2)\n",
      "Validation Neg:251\n",
      "Validation Pos:249\n"
     ]
    }
   ],
   "source": [
    "v_ = validation[:500]\n",
    "print(\"Validation Data:{}\".format(v_.shape))\n",
    "print(\"Validation Neg:{}\".format((v_['sentiment'] == 0.0).sum()))\n",
    "print(\"Validation Pos:{}\".format((v_['sentiment'] == 1.0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the functions used to calculate probability and gradient descent using logistic regression\n",
    "\"\"\"\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1/(1 + np.exp(-x)))\n",
    "\n",
    "def probability(tweet, weights):\n",
    "    w = np.transpose(weights)\n",
    "    return sigmoid(np.dot(tweet, weights))\n",
    "    \n",
    "def cost_derivative(features, targets, prob, weights, penalty):\n",
    "    error = prob-targets\n",
    "    err = float(error)\n",
    "    b = penalty*weights\n",
    "    feat = np.transpose(features)\n",
    "    a = err*feat\n",
    "    aa = np.array(a)\n",
    "    bb = np.reshape(b, (b.shape[0], 1))\n",
    "    result = aa + bb\n",
    "    return result\n",
    "    \n",
    "def update_weights(weights, lr, error):\n",
    "    prod = lr * error\n",
    "    p = np.array(prod)\n",
    "    ww = np.reshape(weights, (weights.shape[0], 1))\n",
    "    www = np.array(ww)\n",
    "    w = www - p\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 850276])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "create tensor to hold encoded tweets in batch size of 100\n",
    "\"\"\"\n",
    "ten = pd.concat([encoded]*100)\n",
    "featurestensor = torch.tensor(ten.values.astype(np.int32))\n",
    "print(featurestensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280000, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = train['sentiment']\n",
    "t = pd.DataFrame(t)\n",
    "a = np.array(t)\n",
    "traintensor = torch.tensor(a.astype(np.int32))\n",
    "traintensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = torch.tensor(train['sentiment'].values.astype(np.int32))\n",
    "train_index = torch.tensor(train.index.values.astype(np.int32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = torch.utils.data.TensorDataset(train_index, train_target) \n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "validation function will allow us to see how our model is predicting sentiments while it trains\n",
    "\"\"\"\n",
    "def valid(weights, validation):\n",
    "    \n",
    "    correct = 0\n",
    "    total = validation.shape[0]\n",
    "    \n",
    "    for i in range(validation.shape[0]):\n",
    "        row = validation.iloc[i]\n",
    "        target = row['sentiment']\n",
    "        zero_encode = encoded.copy()\n",
    "        features = oneHot_encode(zero_encode, row)\n",
    "        \n",
    "        if weights.shape[0] != features.shape[1]:\n",
    "            w = np.transpose(weights)\n",
    "        else:\n",
    "            w = weights\n",
    "                \n",
    "        score = sigmoid(np.dot(features, w))\n",
    "        \n",
    "        pred = 0\n",
    "        if (score > 0.5):\n",
    "            pred = 1\n",
    "        if (pred == target):\n",
    "            correct += 1\n",
    "            \n",
    "    return 100*(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function that trains the training dataset using logistic regression and gradient descent\n",
    "\"\"\"\n",
    "\n",
    "def train_model(trainloader, featurestensor, epochs, learnrate, penalty, words):\n",
    "    start_time = time.time()\n",
    "    steps = 0\n",
    "    e = 0\n",
    "    print_every = 50\n",
    "    batch_size = 100\n",
    "\n",
    "    n_tweets, n_features = featurestensor.shape\n",
    "    \n",
    "    weights = np.random.normal(scale = 1/n_features**.5, size = n_features)\n",
    "\n",
    "    while e < epochs:\n",
    "        running_loss = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        train_sample = trainloader.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "        for i in range(n_tweets):\n",
    "            \n",
    "            original = words.copy()\n",
    "            \n",
    "            row = train_sample.iloc[i]\n",
    "            \n",
    "            features = oneHot_encode(original, row)\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            target = row['sentiment']\n",
    "            \n",
    "            if weights.shape[0] != features.shape[1]:\n",
    "                w = np.transpose(weights)\n",
    "            else:\n",
    "                w = weights\n",
    "            \n",
    "            probability = sigmoid(np.dot(features, w))\n",
    "            error = cost_derivative(features, target, probability, weights, penalty)\n",
    "            \n",
    "            if steps % print_every == 0:\n",
    "                print(\"Epoch:{}/{} ---------- Validation: {}%\".format(e+1, epochs, np.round(valid(w, v_), 2)))\n",
    "\n",
    "        weights = update_weights(weights, learnrate, error)   \n",
    "        \n",
    "        # next epoch\n",
    "        e += 1\n",
    "\n",
    "    #if e % (epochs / 2) == 0:\n",
    "            \n",
    "        #print(\"Epoch: {} --------- Validation: {}\".format(e+1, valid(weights)))\n",
    "        #print(\"Epoch: {}\".format(e + 1))\n",
    "        #print(\"=========\")\n",
    "    end_time = time.time()\n",
    "    print(\"Finished training!\")\n",
    "    print(\"Time Elapsed: {}\".format(np.round(end_time - start_time, 2)))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = train_model(clean_train, featurestensor, 4, 0.001, 0.07, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save weights array in a csv\n",
    "\"\"\"\n",
    "weights_csv = pd.DataFrame(weights)\n",
    "weights_csv.to_csv('weights_4_epoch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(weights, test, encode):\n",
    "    correct = 0\n",
    "    total = test.shape[0]\n",
    "    \n",
    "    for i in range(test.shape[0]):\n",
    "        row = test.iloc[i]\n",
    "        target = row['sentiment']\n",
    "        zero_encode = encode.copy()\n",
    "        features = oneHot_encode(zero_encode, row)\n",
    "        \n",
    "        if weights.shape[0] != features.shape[1]:\n",
    "            w = np.transpose(weights)\n",
    "        else:\n",
    "            w = weights\n",
    "                \n",
    "        score = sigmoid(np.dot(features, w))\n",
    "        \n",
    "        pred = 0\n",
    "        if (score > 0.5):\n",
    "            pred = 1\n",
    "        if (pred == target):\n",
    "            correct += 1\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"Current Example: {} ------ Accuracy: {}\".format(i, 100*(correct/(i+1))))\n",
    "    \n",
    "    print('Final Accuracy: {0}'.format((correct/total)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = test[500:1000]\n",
    "pos = test[220000:220500]\n",
    "\n",
    "#neg = test[479900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1465247</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[itssb, loolgud, afternoonhow, u, doin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465248</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[love, kitty, funny, watching, try, catch, fly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465269</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[watching, french, open, final, chijmes, annie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465274</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[kapsali, thanks, i, meant, euwide, results, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465275</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[strawberries, â¥, yummy, grandma, brought, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet\n",
       "1465247        1.0            [itssb, loolgud, afternoonhow, u, doin]\n",
       "1465248        1.0    [love, kitty, funny, watching, try, catch, fly]\n",
       "1465269        1.0  [watching, french, open, final, chijmes, annie...\n",
       "1465274        1.0  [kapsali, thanks, i, meant, euwide, results, t...\n",
       "1465275        1.0  [strawberries, â¥, yummy, grandma, brought, 4..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_pos = pd.concat([pos, neg])\n",
    "#neg_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = neg_pos.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467599</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[back, behind, dm, 2000, today, boys, girls, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[via, theleadguy, hey, there, great, meet, my,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[ivyclark, name, ironic, first, used, 10204, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[starting, short, lunch, break, must, short, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[hot, outside, ice, cream, time, whats, catch,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                              tweet\n",
       "1467599        1.0  [back, behind, dm, 2000, today, boys, girls, i...\n",
       "1466191        1.0  [via, theleadguy, hey, there, great, meet, my,...\n",
       "4114           0.0  [ivyclark, name, ironic, first, used, 10204, s...\n",
       "4717           0.0  [starting, short, lunch, break, must, short, p...\n",
       "6369           0.0  [hot, outside, ice, cream, time, whats, catch,..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[ivyclark, name, ironic, first, used, 10204, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                              tweet\n",
       "4114        0.0  [ivyclark, name, ironic, first, used, 10204, s..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = neg_pos[neg_pos.index == 4114]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Example: 0 ------ Accuracy: 100.0\n",
      "Current Example: 100 ------ Accuracy: 51.48514851485149\n",
      "Current Example: 200 ------ Accuracy: 51.741293532338304\n",
      "Current Example: 300 ------ Accuracy: 50.83056478405316\n",
      "Current Example: 400 ------ Accuracy: 50.374064837905244\n",
      "Current Example: 500 ------ Accuracy: 51.49700598802395\n",
      "Current Example: 600 ------ Accuracy: 51.08153078202995\n",
      "Current Example: 700 ------ Accuracy: 51.06990014265336\n",
      "Current Example: 800 ------ Accuracy: 51.186017478152316\n",
      "Current Example: 900 ------ Accuracy: 50.943396226415096\n",
      "Final Accuracy: 51.5\n"
     ]
    }
   ],
   "source": [
    "acc(w, testing, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sap] *",
   "language": "python",
   "name": "conda-env-sap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
